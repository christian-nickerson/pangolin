# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: transformers.proto
# Protobuf Python Version: 5.26.1
"""Generated protocol buffer code."""

from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x12transformers.proto\x12\x10\x45mbeddingService"4\n\x10InferenceRequest\x12\x0c\n\x04text\x18\x01 \x03(\t\x12\x12\n\nmodel_name\x18\x02 \x01(\t"\'\n\x11InferenceResponse\x12\x12\n\nembeddings\x18\x01 \x03(\x01"\x12\n\x10ModelListRequest"(\n\x11ModelListResponse\x12\x13\n\x0bmodel_names\x18\x01 \x03(\t2\xc2\x01\n\x14SentenceTransformers\x12T\n\tInference\x12".EmbeddingService.InferenceRequest\x1a#.EmbeddingService.InferenceResponse\x12T\n\tModelList\x12".EmbeddingService.ModelListRequest\x1a#.EmbeddingService.ModelListResponseb\x06proto3'
)

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, "transformers_pb2", _globals)
if not _descriptor._USE_C_DESCRIPTORS:
    DESCRIPTOR._loaded_options = None
    _globals["_INFERENCEREQUEST"]._serialized_start = 40
    _globals["_INFERENCEREQUEST"]._serialized_end = 92
    _globals["_INFERENCERESPONSE"]._serialized_start = 94
    _globals["_INFERENCERESPONSE"]._serialized_end = 133
    _globals["_MODELLISTREQUEST"]._serialized_start = 135
    _globals["_MODELLISTREQUEST"]._serialized_end = 153
    _globals["_MODELLISTRESPONSE"]._serialized_start = 155
    _globals["_MODELLISTRESPONSE"]._serialized_end = 195
    _globals["_SENTENCETRANSFORMERS"]._serialized_start = 198
    _globals["_SENTENCETRANSFORMERS"]._serialized_end = 392
# @@protoc_insertion_point(module_scope)
